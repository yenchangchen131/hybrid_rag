#!/usr/bin/env python
"""
æ‰¹æ¬¡åŸ·è¡Œæ‰€æœ‰æŸ¥è©¢ä¸¦å„²å­˜çµæœ

ä½¿ç”¨æ–¹å¼ï¼š
    uv run python scripts/run_all_queries.py
    uv run python scripts/run_all_queries.py --mode vector
    uv run python scripts/run_all_queries.py --mode keyword
    uv run python scripts/run_all_queries.py --mode hybrid
"""

import argparse
import json
import time
from pathlib import Path
from datetime import datetime

from tqdm import tqdm

from services import RAGService
from core.config import settings
from models.document import QueryModel


VALID_MODES = ["vector", "keyword", "hybrid"]


def load_queries(file_path: Path) -> list[QueryModel]:
    """è¼‰å…¥æ¸¬è©¦æŸ¥è©¢"""
    with open(file_path, "r", encoding="utf-8") as f:
        data = json.load(f)
    return [QueryModel(**q) for q in data]


def run_all_queries(
    queries: list[QueryModel], 
    rag: RAGService, 
    top_k: int = 5,
    mode: str = "hybrid",
) -> list[dict]:
    """åŸ·è¡Œæ‰€æœ‰æŸ¥è©¢"""
    results = []
    total_time = 0.0
    
    for query in tqdm(queries, desc=f"åŸ·è¡ŒæŸ¥è©¢ ({mode})"):
        # è¨ˆæ™‚é–‹å§‹
        start_time = time.perf_counter()
        
        response = rag.answer(query.question, top_k=top_k, mode=mode)
        
        # è¨ˆæ™‚çµæŸ
        elapsed_time = time.perf_counter() - start_time
        total_time += elapsed_time
        
        result = {
            "question_id": query.question_id,
            "question": query.question,
            "question_type": query.question_type,
            "source_dataset": query.source_dataset,
            "gold_answer": query.gold_answer,
            "gold_doc_ids": query.gold_doc_ids,
            "generated_answer": response.answer,
            "retrieved_doc_ids": response.retrieved_doc_ids,
            "retrieved_contexts": [
                {
                    "doc_id": ctx.doc_id,
                    "score": ctx.score,
                    "original_source": ctx.original_source,
                    "content_preview": ctx.content[:200] + "..." if len(ctx.content) > 200 else ctx.content,
                }
                for ctx in response.contexts
            ],
            "response_time_ms": round(elapsed_time * 1000, 2),
        }
        results.append(result)
    
    avg_time = (total_time / len(queries)) * 1000 if queries else 0
    print(f"\nâ±ï¸  å¹³å‡å›æ‡‰æ™‚é–“: {avg_time:.2f} ms")
    
    return results, total_time


def main():
    parser = argparse.ArgumentParser(description="æ‰¹æ¬¡åŸ·è¡Œæ‰€æœ‰æŸ¥è©¢")
    parser.add_argument(
        "--queries",
        type=str,
        default=None,
        help=f"queries.json è·¯å¾‘ (é è¨­: {settings.queries_path})"
    )
    parser.add_argument(
        "--output", "-o",
        type=str,
        default=None,
        help="è¼¸å‡ºçµæœæª”æ¡ˆè·¯å¾‘ (é è¨­: data/rag_results_{mode}.json)"
    )
    parser.add_argument(
        "--mode", "-m",
        type=str,
        default="hybrid",
        choices=VALID_MODES,
        help="æª¢ç´¢æ¨¡å¼: vector, keyword, hybrid (é è¨­: hybrid)"
    )
    parser.add_argument(
        "--top-k", "-k",
        type=int,
        default=5,
        help="æª¢ç´¢æ•¸é‡ (é è¨­: 5)"
    )
    
    args = parser.parse_args()
    
    queries_path = Path(args.queries) if args.queries else settings.queries_path
    
    # æ ¹æ“š mode è‡ªå‹•å‘½åè¼¸å‡ºæª”æ¡ˆ
    if args.output:
        output_path = Path(args.output)
    else:
        output_path = Path(f"data/rag_results_{args.mode}.json")
    
    print("=" * 50)
    print("ğŸ”„ æ‰¹æ¬¡åŸ·è¡Œ RAG æŸ¥è©¢")
    print("=" * 50)
    print(f"ğŸ“Œ æª¢ç´¢æ¨¡å¼: {args.mode}")
    
    # è¼‰å…¥æŸ¥è©¢
    print(f"ğŸ“‚ è¼‰å…¥æŸ¥è©¢: {queries_path}")
    queries = load_queries(queries_path)
    print(f"   å…± {len(queries)} ç­†å•é¡Œ")
    
    # åˆå§‹åŒ– RAGï¼ˆæ ¹æ“šæ¨¡å¼æ±ºå®šæ˜¯å¦è¼‰å…¥å‘é‡ç´¢å¼•ï¼‰
    rag = RAGService()
    rag.initialize(mode=args.mode)
    
    # åŸ·è¡ŒæŸ¥è©¢
    results, total_time = run_all_queries(queries, rag, top_k=args.top_k, mode=args.mode)
    
    # å„²å­˜çµæœ
    output_data = {
        "metadata": {
            "queries_file": str(queries_path),
            "total_questions": len(results),
            "top_k": args.top_k,
            "retrieval_mode": args.mode,
            "total_time_seconds": round(total_time, 2),
            "avg_response_time_ms": round((total_time / len(results)) * 1000, 2) if results else 0,
            "timestamp": datetime.now().isoformat(),
        },
        "results": results,
    }
    
    output_path.parent.mkdir(parents=True, exist_ok=True)
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)
    
    print("=" * 50)
    print(f"âœ… å®Œæˆï¼å…±è™•ç† {len(results)} ç­†å•é¡Œ")
    print(f"ğŸ’¾ çµæœå·²å„²å­˜è‡³: {output_path}")
    print("=" * 50)
    print("\nåŸ·è¡Œä»¥ä¸‹æŒ‡ä»¤è¨ˆç®—è©•ä¼°æŒ‡æ¨™ï¼š")
    print(f"  uv run python scripts/calculate_metrics.py --input {output_path}")


if __name__ == "__main__":
    main()
