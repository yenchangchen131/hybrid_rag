#!/usr/bin/env python
"""
è¨ˆç®—è©•ä¼°æŒ‡æ¨™

å¾ RAG çµæœæª”æ¡ˆè¨ˆç®—å„é …æŒ‡æ¨™ï¼ŒåŒ…æ‹¬ï¼š
- Hit Rate (åƒ…é‡å° single gold doc çš„å•é¡Œ)
- Partial Hit Rate: å°æ–¼å¤šå€‹ gold_doc_ids çš„å•é¡Œï¼Œè¨ˆç®— å‘½ä¸­æ•¸/ç¸½æ•¸
- MRR (Mean Reciprocal Rank): æ’åºç²¾æº–åº¦æŒ‡æ¨™
- æŒ‰å•é¡Œé¡å‹åˆ†çµ„çµ±è¨ˆ (single-hop vs multi-hop)
- æŒ‰è³‡æ–™ä¾†æºåˆ†çµ„çµ±è¨ˆ

ä½¿ç”¨æ–¹å¼ï¼š
    uv run python scripts/calculate_metrics.py
    uv run python scripts/calculate_metrics.py --input data/rag_results.json
"""

import argparse
import json
from pathlib import Path
from collections import defaultdict


def calculate_reciprocal_rank(gold_ids: set, retrieved_ids: list) -> float:
    """è¨ˆç®— Reciprocal Rankï¼ˆå¹³å‡ï¼‰
    
    å°æ–¼å¤šå€‹ gold docsï¼Œè¨ˆç®—æ¯å€‹ gold doc çš„ RR å¾Œå–å¹³å‡ã€‚
    å¦‚æœæŸå€‹ gold doc æ²’æœ‰è¢«æª¢ç´¢åˆ°ï¼Œè©² doc çš„ RR = 0
    """
    if not gold_ids:
        return 0.0
    
    rr_sum = 0.0
    for gold_id in gold_ids:
        for rank, doc_id in enumerate(retrieved_ids, start=1):
            if doc_id == gold_id:
                rr_sum += 1.0 / rank
                break
        # å¦‚æœæ²’æ‰¾åˆ°ï¼ŒRR = 0ï¼Œä¸éœ€é¡å¤–è™•ç†
    
    return rr_sum / len(gold_ids)


def calculate_metrics(results: list[dict]) -> dict:
    """è¨ˆç®—è©•ä¼°æŒ‡æ¨™"""
    
    # åˆ†é–‹çµ±è¨ˆï¼šå–®ä¸€ gold doc vs å¤šå€‹ gold docs
    single_gold_results = []  # åªæœ‰ä¸€å€‹ gold doc
    multi_gold_results = []   # å¤šå€‹ gold docs
    
    # æ•´é«”çµ±è¨ˆ
    total_gold_docs = 0
    total_hit_docs = 0
    total_rr = 0.0  # ç”¨æ–¼è¨ˆç®— MRR
    
    # æŒ‰å•é¡Œé¡å‹åˆ†çµ„
    by_question_type = defaultdict(lambda: {
        "total": 0, "gold_docs": 0, "hit_docs": 0, "rr_sum": 0.0,
        "single_gold_hits": 0, "single_gold_total": 0
    })
    
    # æŒ‰è³‡æ–™ä¾†æºåˆ†çµ„
    by_source = defaultdict(lambda: {
        "total": 0, "gold_docs": 0, "hit_docs": 0, "rr_sum": 0.0,
        "single_gold_hits": 0, "single_gold_total": 0
    })
    
    # è©³ç´°çµæœ
    detailed_results = []
    
    for r in results:
        gold_ids = set(r["gold_doc_ids"])
        retrieved_ids = r["retrieved_doc_ids"]
        
        # è¨ˆç®—å‘½ä¸­
        hit_ids = gold_ids.intersection(retrieved_ids)
        hit_count = len(hit_ids)
        gold_count = len(gold_ids)
        is_hit = hit_count > 0
        
        # Reciprocal Rank
        rr = calculate_reciprocal_rank(gold_ids, retrieved_ids)
        total_rr += rr
        
        # éƒ¨åˆ†å‘½ä¸­ç‡å­—ä¸² (ä¾‹å¦‚ "2/5")
        partial_hit_str = f"{hit_count}/{gold_count}"
        partial_hit_rate = hit_count / gold_count if gold_count > 0 else 0
        
        # ç´¯åŠ æ•´é«”çµ±è¨ˆ
        total_gold_docs += gold_count
        total_hit_docs += hit_count
        
        # åˆ†é¡ï¼šå–®ä¸€ vs å¤šå€‹ gold doc
        if gold_count == 1:
            single_gold_results.append(r)
        else:
            multi_gold_results.append(r)
        
        # åˆ†çµ„çµ±è¨ˆ
        q_type = r.get("question_type", "unknown")
        by_question_type[q_type]["total"] += 1
        by_question_type[q_type]["gold_docs"] += gold_count
        by_question_type[q_type]["hit_docs"] += hit_count
        by_question_type[q_type]["rr_sum"] += rr
        if gold_count == 1:
            by_question_type[q_type]["single_gold_total"] += 1
            if is_hit:
                by_question_type[q_type]["single_gold_hits"] += 1
        
        source = r.get("source_dataset", "unknown")
        by_source[source]["total"] += 1
        by_source[source]["gold_docs"] += gold_count
        by_source[source]["hit_docs"] += hit_count
        by_source[source]["rr_sum"] += rr
        if gold_count == 1:
            by_source[source]["single_gold_total"] += 1
            if is_hit:
                by_source[source]["single_gold_hits"] += 1
        
        # è©³ç´°çµæœ
        detailed_results.append({
            "question_id": r["question_id"],
            "question": r["question"],
            "question_type": q_type,
            "source_dataset": source,
            "gold_count": gold_count,
            "gold_doc_ids": list(gold_ids),
            "retrieved_doc_ids": retrieved_ids,
            "hit_doc_ids": list(hit_ids),
            "partial_hit": partial_hit_str,
            "partial_hit_rate": round(partial_hit_rate, 4),
            "reciprocal_rank": round(rr, 4),
        })
    
    # è¨ˆç®—å–®ä¸€ gold doc çš„ hit rate
    single_gold_hits = sum(1 for r in single_gold_results 
                          if set(r["gold_doc_ids"]).intersection(r["retrieved_doc_ids"]))
    single_gold_total = len(single_gold_results)
    
    # MRR
    total = len(results)
    mrr = total_rr / total if total > 0 else 0
    
    # è¨ˆç®—åˆ†çµ„çµ±è¨ˆçš„æ¯”ç‡
    def calc_group_stats(group: dict) -> dict:
        stats = {
            "total_questions": group["total"],
            "total_gold_docs": group["gold_docs"],
            "total_hit_docs": group["hit_docs"],
            "partial_hit_rate": round(group["hit_docs"] / group["gold_docs"], 4) if group["gold_docs"] > 0 else 0,
            "mrr": round(group["rr_sum"] / group["total"], 4) if group["total"] > 0 else 0,
        }
        # åªæœ‰ç•¶æœ‰å–®ä¸€ gold doc çš„å•é¡Œæ™‚æ‰é¡¯ç¤º hit rate
        if group["single_gold_total"] > 0:
            stats["single_gold_questions"] = group["single_gold_total"]
            stats["single_gold_hit_rate"] = round(group["single_gold_hits"] / group["single_gold_total"], 4)
        return stats
    
    return {
        "summary": {
            "total_questions": total,
            # å–®ä¸€ gold doc çš„ hit rateï¼ˆé¿å…å¤š gold doc çš„èª¤å°ï¼‰
            "single_gold_questions": single_gold_total,
            "single_gold_hit_rate": round(single_gold_hits / single_gold_total, 4) if single_gold_total > 0 else None,
            # å¤š gold doc çš„ partial hit rate
            "multi_gold_questions": len(multi_gold_results),
            "total_gold_docs": total_gold_docs,
            "total_hit_docs": total_hit_docs,
            "partial_hit_rate": round(total_hit_docs / total_gold_docs, 4) if total_gold_docs > 0 else 0,
            # æ’åºæŒ‡æ¨™
            "mrr": round(mrr, 4),
        },
        "by_question_type": {k: calc_group_stats(v) for k, v in by_question_type.items()},
        "by_source": {k: calc_group_stats(v) for k, v in by_source.items()},
        "detailed_results": detailed_results,
    }


def print_metrics(metrics: dict) -> None:
    """è¼¸å‡ºæŒ‡æ¨™"""
    summary = metrics["summary"]
    
    # æŒ‰è³‡æ–™ä¾†æºåˆ†çµ„
    print("\n" + "=" * 50)
    print("æŒ‰è³‡æ–™ä¾†æºåˆ†çµ„")
    print("=" * 50)
    for source, stats in metrics["by_source"].items():
        print(f"\nã€{source}ã€‘")
        print(f"  å•é¡Œæ•¸:           {stats['total_questions']}")
        if "single_gold_hit_rate" in stats:
            print(f"  Hit Rate:         {stats['single_gold_hit_rate']:.2%}")
        print(f"  Partial Hit Rate: {stats['partial_hit_rate']:.2%} ({stats['total_hit_docs']}/{stats['total_gold_docs']})")
        print(f"  MRR:              {stats['mrr']:.4f}")
    
    # æŒ‰å•é¡Œé¡å‹åˆ†çµ„
    print("\n" + "=" * 50)
    print("æŒ‰å•é¡Œé¡å‹åˆ†çµ„")
    print("=" * 50)
    for q_type, stats in metrics["by_question_type"].items():
        print(f"\nã€{q_type}ã€‘")
        print(f"  å•é¡Œæ•¸:           {stats['total_questions']}")
        if "single_gold_hit_rate" in stats:
            print(f"  Hit Rate:         {stats['single_gold_hit_rate']:.2%}")
        print(f"  Partial Hit Rate: {stats['partial_hit_rate']:.2%} ({stats['total_hit_docs']}/{stats['total_gold_docs']})")
        print(f"  MRR:              {stats['mrr']:.4f}")
    
    # ç¸½è¨ˆ
    print("\n" + "=" * 50)
    print("ç¸½è¨ˆ")
    print("=" * 50)
    print(f"\n  å•é¡Œæ•¸:           {summary['total_questions']}")
    if summary["single_gold_hit_rate"] is not None:
        print(f"  Hit Rate:         {summary['single_gold_hit_rate']:.2%}")
    print(f"  Partial Hit Rate: {summary['partial_hit_rate']:.2%} ({summary['total_hit_docs']}/{summary['total_gold_docs']})")
    print(f"  MRR:              {summary['mrr']:.4f}")
    print("")


def main():
    parser = argparse.ArgumentParser(description="è¨ˆç®— RAG è©•ä¼°æŒ‡æ¨™")
    parser.add_argument(
        "--input", "-i",
        type=str,
        default="data/rag_results_hybrid.json",
        help="RAG çµæœæª”æ¡ˆè·¯å¾‘"
    )
    parser.add_argument(
        "--output", "-o",
        type=str,
        default=None,
        help="æŒ‡æ¨™è¼¸å‡ºæª”æ¡ˆè·¯å¾‘ (é è¨­: æ ¹æ“š input è‡ªå‹•å‘½å)"
    )
    
    args = parser.parse_args()
    
    input_path = Path(args.input)
    
    # è‡ªå‹•æ ¹æ“š input æª”åæ¨æ–· output æª”å
    # rag_results_hybrid.json â†’ evaluation_metrics_hybrid.json
    if args.output:
        output_path = Path(args.output)
    else:
        input_name = input_path.stem  # e.g. "rag_results_hybrid"
        mode_suffix = input_name.replace("rag_results_", "")  # e.g. "hybrid"
        output_path = input_path.parent / f"evaluation_metrics_{mode_suffix}.json"
    
    print("=" * 60)
    print("ğŸ”¬ è¨ˆç®— RAG è©•ä¼°æŒ‡æ¨™")
    print("=" * 60)
    
    # è¼‰å…¥çµæœ
    print(f"ğŸ“‚ è¼‰å…¥çµæœ: {input_path}")
    with open(input_path, "r", encoding="utf-8") as f:
        data = json.load(f)
    
    results = data.get("results", data)  # ç›¸å®¹èˆŠæ ¼å¼
    print(f"   å…± {len(results)} ç­†çµæœ")
    
    # è¨ˆç®—æŒ‡æ¨™
    metrics = calculate_metrics(results)
    
    # è¼¸å‡ºåˆ°çµ‚ç«¯
    print_metrics(metrics)
    
    # å„²å­˜çµæœ
    output_path.parent.mkdir(parents=True, exist_ok=True)
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(metrics, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ è©³ç´°æŒ‡æ¨™å·²å„²å­˜è‡³: {output_path}")


if __name__ == "__main__":
    main()
