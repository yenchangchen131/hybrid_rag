"""
Hybrid RAG è©•ä¼°å„€è¡¨æ¿

Streamlit å‰ç«¯æ‡‰ç”¨ç¨‹å¼

ä½¿ç”¨æ–¹å¼ï¼š
    uv run streamlit run app.py
"""

import json
import time
from pathlib import Path
from datetime import datetime

import streamlit as st
import pandas as pd

from services import RAGService
from core.config import settings
from models.document import QueryModel


# é é¢é…ç½®
st.set_page_config(
    page_title="Hybrid RAG è©•ä¼°å„€è¡¨æ¿",
    page_icon="ğŸ”",
    layout="wide",
)

# åˆå§‹åŒ– session state
if "rag_service" not in st.session_state:
    st.session_state.rag_service = None
if "results" not in st.session_state:
    st.session_state.results = {}  # {mode: results}
if "current_mode" not in st.session_state:
    st.session_state.current_mode = None


def load_queries() -> list[QueryModel]:
    """è¼‰å…¥æŸ¥è©¢"""
    with open(settings.queries_path, "r", encoding="utf-8") as f:
        data = json.load(f)
    return [QueryModel(**q) for q in data]


def run_evaluation(queries: list[QueryModel], mode: str, top_k: int) -> list[dict]:
    """åŸ·è¡Œè©•ä¼°"""
    rag = st.session_state.rag_service
    if rag is None:
        rag = RAGService()
        st.session_state.rag_service = rag
    
    rag.initialize(mode=mode)
    
    results = []
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for i, query in enumerate(queries):
        status_text.text(f"è™•ç†ä¸­: {i+1}/{len(queries)}")
        
        start_time = time.perf_counter()
        response = rag.answer(query.question, top_k=top_k, mode=mode)
        elapsed_time = time.perf_counter() - start_time
        
        gold_ids = set(query.gold_doc_ids)
        retrieved_ids = set(response.retrieved_doc_ids)
        hit_ids = gold_ids.intersection(retrieved_ids)
        
        result = {
            "question_id": query.question_id,
            "question": query.question,
            "question_type": query.question_type,
            "source_dataset": query.source_dataset,
            "gold_answer": query.gold_answer,
            "gold_doc_ids": query.gold_doc_ids,
            "generated_answer": response.answer,
            "retrieved_doc_ids": response.retrieved_doc_ids,
            "contexts": [
                {
                    "doc_id": ctx.doc_id,
                    "score": ctx.score,
                    "content": ctx.content,
                    "original_source": ctx.original_source,
                }
                for ctx in response.contexts
            ],
            "hit_count": len(hit_ids),
            "gold_count": len(gold_ids),
            "partial_hit": f"{len(hit_ids)}/{len(gold_ids)}",
            "is_hit": len(hit_ids) > 0,
            "response_time_ms": round(elapsed_time * 1000, 2),
        }
        results.append(result)
        progress_bar.progress((i + 1) / len(queries))
    
    status_text.text("âœ… å®Œæˆ!")
    return results


def calculate_metrics(results: list[dict]) -> dict:
    """è¨ˆç®—æŒ‡æ¨™"""
    total = len(results)
    
    # æ•´é«”çµ±è¨ˆ
    total_hits = sum(1 for r in results if r["is_hit"])
    total_gold_docs = sum(r["gold_count"] for r in results)
    total_hit_docs = sum(r["hit_count"] for r in results)
    avg_time = sum(r["response_time_ms"] for r in results) / total if total > 0 else 0
    
    # å–®ä¸€ gold doc çš„ hit rate
    single_gold = [r for r in results if r["gold_count"] == 1]
    single_hits = sum(1 for r in single_gold if r["is_hit"])
    
    # MRR
    def calc_mrr(results):
        total_rr = 0
        for r in results:
            gold_ids = set(r["gold_doc_ids"])
            rr_sum = 0
            for gold_id in gold_ids:
                for rank, doc_id in enumerate(r["retrieved_doc_ids"], start=1):
                    if doc_id == gold_id:
                        rr_sum += 1.0 / rank
                        break
            total_rr += rr_sum / len(gold_ids) if gold_ids else 0
        return total_rr / len(results) if results else 0
    
    return {
        "total_questions": total,
        "hit_rate": total_hits / total if total > 0 else 0,
        "single_gold_hit_rate": single_hits / len(single_gold) if single_gold else 0,
        "partial_hit_rate": total_hit_docs / total_gold_docs if total_gold_docs > 0 else 0,
        "mrr": calc_mrr(results),
        "avg_response_time_ms": avg_time,
    }


def display_metrics_comparison():
    """é¡¯ç¤ºæŒ‡æ¨™æ¯”è¼ƒ"""
    if not st.session_state.results:
        st.info("å°šç„¡è©•ä¼°çµæœï¼Œè«‹å…ˆåŸ·è¡Œè©•ä¼°ã€‚")
        return
    
    # è¨ˆç®—å„æ¨¡å¼æŒ‡æ¨™
    metrics_data = []
    for mode, results in st.session_state.results.items():
        metrics = calculate_metrics(results)
        metrics["mode"] = mode
        metrics_data.append(metrics)
    
    df = pd.DataFrame(metrics_data)
    df = df.set_index("mode")
    
    # æ ¼å¼åŒ–é¡¯ç¤º
    st.subheader("ğŸ“Š æŒ‡æ¨™æ¯”è¼ƒ")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ç¸½é¡Œæ•¸", df["total_questions"].iloc[0])
    
    # é¡¯ç¤ºå„æ¨¡å¼çš„æŒ‡æ¨™
    for mode in df.index:
        st.markdown(f"### {mode.upper()}")
        cols = st.columns(5)
        cols[0].metric("Hit Rate", f"{df.loc[mode, 'hit_rate']:.2%}")
        cols[1].metric("Single Gold Hit Rate", f"{df.loc[mode, 'single_gold_hit_rate']:.2%}")
        cols[2].metric("Partial Hit Rate", f"{df.loc[mode, 'partial_hit_rate']:.2%}")
        cols[3].metric("MRR", f"{df.loc[mode, 'mrr']:.4f}")
        cols[4].metric("Avg Response Time", f"{df.loc[mode, 'avg_response_time_ms']:.0f} ms")


def display_results_table(mode: str):
    """é¡¯ç¤ºçµæœè¡¨æ ¼"""
    if mode not in st.session_state.results:
        return
    
    results = st.session_state.results[mode]
    
    # è½‰æ›ç‚º DataFrame
    df = pd.DataFrame([
        {
            "ID": r["question_id"][:8],
            "å•é¡Œ": r["question"][:50] + "..." if len(r["question"]) > 50 else r["question"],
            "é¡å‹": r["question_type"],
            "ä¾†æº": r["source_dataset"],
            "å‘½ä¸­": r["partial_hit"],
            "æ˜¯å¦å‘½ä¸­": "âœ…" if r["is_hit"] else "âŒ",
            "æ™‚é–“(ms)": r["response_time_ms"],
        }
        for r in results
    ])
    
    st.dataframe(df, use_container_width=True)


def display_question_detail(mode: str, question_idx: int):
    """é¡¯ç¤ºå•é¡Œè©³æƒ…"""
    if mode not in st.session_state.results:
        return
    
    result = st.session_state.results[mode][question_idx]
    
    st.markdown("---")
    st.subheader(f"ğŸ“ å•é¡Œè©³æƒ…")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**å•é¡Œ:**")
        st.write(result["question"])
        
        st.markdown("**æ¨™æº–ç­”æ¡ˆ:**")
        st.info(result["gold_answer"])
        
        st.markdown("**æ¨¡å‹å›ç­”:**")
        st.success(result["generated_answer"])
    
    with col2:
        st.markdown("**Gold Doc IDs:**")
        for doc_id in result["gold_doc_ids"]:
            st.code(doc_id)
        
        st.markdown("**æª¢ç´¢çµæœ:**")
        st.write(f"å‘½ä¸­: {result['partial_hit']}")
        
    # æª¢ç´¢åˆ°çš„æ–‡ä»¶
    st.markdown("### ğŸ“š æª¢ç´¢åˆ°çš„æ–‡ä»¶")
    for i, ctx in enumerate(result["contexts"]):
        is_gold = ctx["doc_id"] in result["gold_doc_ids"]
        icon = "ğŸ¯" if is_gold else "ğŸ“„"
        
        with st.expander(f"{icon} [{i+1}] {ctx['doc_id'][:16]}... (Score: {ctx['score']:.4f})"):
            st.markdown(f"**ä¾†æº:** {ctx['original_source']}")
            st.markdown("**å…§å®¹:**")
            st.write(ctx["content"])


def main():
    st.title("ğŸ” Hybrid RAG è©•ä¼°å„€è¡¨æ¿")
    
    # å´é‚Šæ¬„
    with st.sidebar:
        st.header("âš™ï¸ è¨­å®š")
        
        mode = st.selectbox(
            "æª¢ç´¢æ¨¡å¼",
            ["hybrid", "vector", "keyword"],
            index=0,
        )
        
        top_k = st.slider("Top-K", min_value=1, max_value=20, value=5)
        
        if st.button("ğŸš€ åŸ·è¡Œè©•ä¼°", type="primary", use_container_width=True):
            with st.spinner("è¼‰å…¥æŸ¥è©¢..."):
                queries = load_queries()
            
            st.info(f"æ­£åœ¨ä»¥ {mode} æ¨¡å¼åŸ·è¡Œ {len(queries)} é¡Œ...")
            results = run_evaluation(queries, mode, top_k)
            st.session_state.results[mode] = results
            st.session_state.current_mode = mode
            st.rerun()
        
        st.markdown("---")
        st.markdown("### å·²å®Œæˆçš„è©•ä¼°")
        for m in st.session_state.results.keys():
            st.write(f"âœ… {m}")
    
    # ä¸»å€åŸŸ
    tab1, tab2, tab3 = st.tabs(["ğŸ“Š æŒ‡æ¨™æ¯”è¼ƒ", "ğŸ“‹ çµæœåˆ—è¡¨", "ğŸ” å•é¡Œè©³æƒ…"])
    
    with tab1:
        display_metrics_comparison()
    
    with tab2:
        if st.session_state.results:
            selected_mode = st.selectbox(
                "é¸æ“‡æ¨¡å¼",
                list(st.session_state.results.keys()),
                key="results_mode"
            )
            display_results_table(selected_mode)
        else:
            st.info("è«‹å…ˆåŸ·è¡Œè©•ä¼°ã€‚")
    
    with tab3:
        if st.session_state.results:
            col1, col2 = st.columns([1, 3])
            
            with col1:
                selected_mode = st.selectbox(
                    "æ¨¡å¼",
                    list(st.session_state.results.keys()),
                    key="detail_mode"
                )
                
                question_options = [
                    f"{i+1}. {r['question'][:30]}..."
                    for i, r in enumerate(st.session_state.results[selected_mode])
                ]
                selected_q = st.selectbox("é¸æ“‡å•é¡Œ", question_options, key="detail_q")
                question_idx = question_options.index(selected_q)
            
            with col2:
                display_question_detail(selected_mode, question_idx)
        else:
            st.info("è«‹å…ˆåŸ·è¡Œè©•ä¼°ã€‚")


if __name__ == "__main__":
    main()
